{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Monte Carlo simulation  \n\nThe following tutorial will lead you through an example workflow on how to create a Monte Carlo simulation of \ngeological models, meaning we will produce different geological geometries and also simulate their gravity\nresponse.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing libraries\nFirst things first: let's import necessary libraries.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Importing GemPy\nimport gempy as gp\nfrom gempy.assets import topology as tp\nfrom gempy.bayesian.fields import compute_prob, calculate_ie_masked\nfrom gempy.assets.geophysics import GravityPreprocessing\n\n# Importing auxilary libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-talk')\n\n#import sys\n#sys.path.append('../../OpenWF/')\n#from aux_functions import log_progress\n\n# Check gempy version used for running the code\nprint(f\"Code run with GemPy version: {gp.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Initialization\n\nFirst, we import the base Proof-of-Concept model (POC-model from here on), which was generated in the previous example. Using the loading method of GemPy `gp.load_model()` directly loads the model's input, already set with fault relations, surfaces assigned to a stack (series), etc.\nOnly thing left is to recompile and run the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_path = '../../models/2021-06-04_POC_base_model'\n\ngeo_model = gp.load_model('POC_PCT_model', path=model_path,\n                         recompile=False)\n\n# import DTM\ndtm = np.load('../../models/Graben_base_model_topography.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the method `.get_additional_data()`, we can display a summary of model information and parameters, such as the kriging parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.get_additional_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Changing the kriging parameters affects the resulting models, e.g. the range represents the maximum correlation distance, or reducing the coefficient of correlation will yield a smoother, less \"bumpy\" model. For the POC-model, we set the `range` to 20000 and the correlation coefficient $C_o$ to 200000. Then we set up the interpolator, i.e. compile the functions which will calculate the scalar fields of our model surfaces.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# adapt kriging to the parameters of previous example\n# decrease the kriging range\ngeo_model.modify_kriging_parameters('range', 20000.)\ngeo_model.modify_kriging_parameters('$C_o$', 2e5)\n\n\n# Set the interpolator function\n# Create the theano model\ngp.set_interpolator(geo_model,\n                         compile_theano=True,\n                         theano_optimizer='fast_compile',\n                         verbose=[],\n                         update_kriging=False);\n\n# compute the model\nsol = gp.compute_model(geo_model, compute_mesh=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the model is computed, lets have a look at a cross-section along the y-axis, so across the graben system:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.plot_2d(geo_model, cell_number=25, direction='y', show_data=False, show_topography=False,\n          show_lith=True, show_results=True, show_boundaries=False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The two distinct domains in this model are directly visible: (i) the old graben system (extensional regime), covered by the (ii) thrusted, younger units.\n\n## Add Gravity grid\nIn the previous example, next to creating the model, we chose quasi-random locations for 15 gravity stations. The gravity signal of the base POC-model is simulated at these 15 stations. In the following workflows, we assume that these 15 stations were measured. So they serve as observed data for conditioning the MonteCarlo Ensemble of different geological geometries.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# In[7]:\n\n\ngrav_stations = pd.read_csv('../../data/Data_for_MC/20210322_forw_grav_seed58.csv')\nstation_coordinates = np.stack((grav_stations.X.values, \n                                grav_stations.Y.values, \n                                grav_stations.Z.values), axis=1)\n\nfig = plt.figure(figsize=[11,5])\ncb = plt.scatter(grav_stations['X'], grav_stations['Y'], c=grav_stations['grav'], \n           marker='s', s=90, cmap='viridis')\nplt.colorbar(cb, label='gravity')\nplt.ylabel('y [m]')\nplt.xlabel('x [m]');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These stations are used for creating a centered grid around each station. The centered grid has an extent of 10 cells in x- and y-direction, and 15 cells in the z-direction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.set_centered_grid(station_coordinates,  resolution = [10, 10, 15], radius=6000)\ng = GravityPreprocessing(geo_model.grid.centered_grid)\ntz = g.set_tz_kernel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that there are three active grids. On each, the gravity signal will be calculated. Of course, we can let it be calculated on each grid, but we may not need the information on e.g. the topography grid (which would for instance yield the geological map). \nSo we can set only the centered grid to active, which speeds up the simulation.\n\n**Note** that you'll need to model also the regular grid, if you plan to export the `lith_block` geological voxel model later on! \nAs we want to also have the geometric changes in the lithological grid, we set `reset=False`. If we were to set it to `True`, only the 'centered' grid would be active.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "geo_model.set_active_grid('centered', reset=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The centered grid will now be the only one where the model information is stored, meaning less computational time. Let's have a look how this comes in handy, when we start to modify the depth of units and calculate the gravity.\n\nBefore running the simulations, we need to assign densities to the rock units, otherwise it will raise an error.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# add densities - from abdelfettah 2014 and SAPHYR\ndensities = [0, 0, 0, 0, 0, 2.466, 2.61, 2.53, \n             2.61, 2.47, 2.55, 2.67]\ngeo_model.add_surface_values(densities, ['density'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MC Variation\nFor varying the depth of units, we extract the indices of the units whose input points we want to modify. To guarantee that we always vary the original depth in each realization (and not the depth used in the previous realization), we first generate an initial-depth array, containing the original depth information of all input points:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Z_init = geo_model.surface_points.df['Z'].copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Having all the undisturbed depth values, we extract all surface points belonging to the units whose inputs we want to vary:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "graben_lower = geo_model.surface_points.df.query(\"surface=='Lower-filling'\")\ngraben_middle = geo_model.surface_points.df.query(\"surface=='Upper-filling'\")\nunconformity = geo_model.surface_points.df.query(\"surface=='Unconformity'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before running the Monte Carlo simulations, we set up the interpolator for a \"fast-run\", i.e. it optimizes runtime on cost of compilation time:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.set_interpolator(geo_model, output=['gravity'], \n                    theano_optimizer='fast_run', \n                    update_kriging=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are good to go and run the Monte Carlo simulation. In the following, we fix a numpy random number seed so that this MC-simulation is reproducible\nThen, we create empty arrays and dictionaries for the lithologies and gravity, respectively. In a `for` loop, we then vary depths of interface points and\ncompute a model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n# allocate array for lithology blocks\nlith_blocks = np.array([])\n# create a dictionary to store gravity of simulations\ngrav = dict() \n# get indices where the variable input points are\nLgraben = list(graben_lower.index)\nUgraben = list(graben_middle.index)\nUncon = list(unconformity.index)\nCindices = Lgraben + Ugraben + Uncon\n\n# set number of realizations\nn_iterations = 10\n\nfor i in range(n_iterations):\n    # vary surface points   \n    Z_var = np.random.normal(0, 300, size=3)    \n    Z_loc = np.hstack([Z_init[Lgraben] + Z_var[0],\n                       Z_init[Ugraben] + Z_var[1],\n                       Z_init[Uncon] + Z_var[2]])\n    # apply variation to model\n    geo_model.modify_surface_points(Cindices, Z=Z_loc)\n    # re-compute model\n    gp.compute_model(geo_model)\n    # store lithologies ONLY THERE IF REGULAR GRID IS ACTIVE\n    lith_blocks = np.append(lith_blocks, geo_model.solutions.lith_block)\n    # store gravity\n    grav[f\"Real_{i}\"] = geo_model.solutions.fw_gravity\n\nlith_blocks = lith_blocks.reshape(n_iterations, -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export models and gravity\nFor post-processing of use in different software (e.g. numerical simulators for heat- and mass-transport), knowing ways of exporting the MC-results, in this case the simulated gravity and the lithology-blocks, comes in handy. There are many different ways of saving stuff (e.g. pickle the simulation results), but here we present simple exports as `.csv` and `.npy` files.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gravdf = pd.DataFrame.from_dict(grav)\n\n# add station coordinates to the dataframe\ngravdf[\"X\"] = station_coordinates[:,0]\ngravdf[\"Y\"] = station_coordinates[:,1]\ngravdf[\"Z\"] =station_coordinates[:,2]\n\ngravdf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This can be saved as usual with `df.to_csv('pathname')` using Pandas. For the lithological block model, one good option is to save it as a numpy array, using `numpy.save()`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.save('../../data/outputs/MCexample_10realizations.npy', lith_blocks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick model analysis\nLet's have a quick first look at the resulting gravity and lithological block models. From the gravity dictionary, we can quickly generate a dataframe, convenient for further model analysis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prob_block = gp.bayesian.fields.probability(lith_blocks)\nie_block = gp.bayesian.fields.information_entropy(prob_block)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following plot shows the probability of unit 5 in the probability block. With faults not being excluded, and counting of units starting with 0, we can see that the index 5 relates to the `Lower-filling` surface. The plot shows where to expect the unit. Everywhere, this unit is present throughout the simulations, the probability plot shows a bright yellow (probability = 1). Where it is always absent, we see the dark violet (probability = 0). The blueish-greenish areas are in between, meaning that in some realizations, the `Lower-filling` unit is present there, in other realization it is not.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "layer = 5\ngp.plot_2d(geo_model,\n            show_lith=False, show_boundaries=False, show_data=False,\n            regular_grid=prob_block[layer],\n            kwargs_regular_grid={'cmap': 'viridis',\n                                 'norm': None}\n            );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the for-loop above, we not only varied the bottom boundary of the `Lower-filling` unit, but also `Upper-filling` and `Unconformity`. Using the measure of information entropy, we can visualize the parts of the model, where the most change is happening, i.e. where entropy is largest. Black areas in the following plot have zero information entropy, as there is only one \"microstate\" for the system, i.e. the model ensemble.  \n\nThis means, we'd always encounter the same unit at the same place in every ensemble member. The colored areas, however, are areas where we'd encounter different geological units between ensemble members.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gp.plot_2d(geo_model,\n            show_lith=False, show_boundaries=False, show_data=False,\n            regular_grid=ie_block,\n            kwargs_regular_grid={'cmap': 'magma',\n                                 'norm': None}\n            );"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, let's have a look at the gravity. We'll simply have a look at mean and standard deviation of the simulated gravity of the ensemble:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# make subplots with mean and std\ngravdf_plt = pd.DataFrame.from_dict(grav)\nfig, axs = plt.subplots(1,2, figsize=[15,5], sharey=True)\nm_grav = np.mean(gravdf_plt, axis=1)\nst_grav = np.std(gravdf_plt, axis=1)\n\nm = axs[0].scatter(grav_stations['X'], grav_stations['Y'], c=m_grav, \n           marker='s', s=90, cmap='magma', zorder=2)\naxs[0].contourf(dtm[:,:,0], dtm[:,:,1], dtm[:,:,2],20, cmap='gist_earth', zorder=0)\naxs[0].contour(dtm[:,:,0], dtm[:,:,1], dtm[:,:,2],10, colors='gray', zorder=1)\ns = axs[1].scatter(grav_stations['X'], grav_stations['Y'], c=st_grav,\n              marker='s', s=90, cmap='magma', zorder=2)\naxs[1].contourf(dtm[:,:,0], dtm[:,:,1], dtm[:,:,2],20, cmap='gist_earth', zorder=0)\naxs[1].contour(dtm[:,:,0], dtm[:,:,1], dtm[:,:,2],10, colors='gray', zorder=1)\nfig.colorbar(m, ax=axs[0], label='gravity')\nfig.colorbar(s, ax=axs[1], label='std of gravity')\naxs[0].set_title('Ensemble mean')\naxs[1].set_title('Ensemble standard deviation')\naxs[0].set_ylabel('Y [m]')\naxs[0].set_xlabel('X [m]')\naxs[1].set_xlabel('X [m]')\n\nfig.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}